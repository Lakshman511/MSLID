{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiments with duration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lakshman511/MSLID/blob/master/ColabNotebooks/Experiments_with_duration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXmkikiwRjRX",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92SfXcTqVagW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdccb3b2-61dc-462a-be8d-49178bc21382"
      },
      "source": [
        "!pip install --pre torchaudio -f https://download.pytorch.org/whl/nightly/torch_nightly.html\n",
        "#!pip install torchaudio\n",
        "#!pip install git+git://github.com/pytorch/audio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/torch_nightly.html\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.6/dist-packages (0.7.0.dev20200910)\n",
            "Requirement already satisfied: torch==1.7.0.dev20200910+cu92 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.7.0.dev20200910+cu92)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0.dev20200910+cu92->torchaudio) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0.dev20200910+cu92->torchaudio) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0.dev20200910+cu92->torchaudio) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0.dev20200910+cu92->torchaudio) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptvYlvuvT_eh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1d00d5-68b8-4e8b-ad24-f19de15b03c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXF1_wWQReQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "import torchaudio\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QS9Z7iTEaeq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db14945-db1c-4a7d-88af-dc4c8290c0d3"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGAiTLoTUmvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile('/content/drive/My Drive/Languages.zip', mode='r') as input:\n",
        "  input.extractall(\".\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay3e4qybvSW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import torchaudio\n",
        "\n",
        "def prepareData(root, classes, datatype=\"train\", duration=2, overlap=0.25, file_save=\"file.txt\"):\n",
        "    dataset = []\n",
        "    for L in classes.keys():\n",
        "        if datatype == \"train\":\n",
        "            path = root + \"/\" + L + \"/\" + L + \"_Train/\"\n",
        "        else:\n",
        "            path = root + \"/\" + L + \"/\" + L + \"_Test/\"\n",
        "        tempdata = [(path+f, classes[L]) for f in os.listdir(path)]\n",
        "\n",
        "        for x in tempdata:\n",
        "            waveform, samplerate = torchaudio.load(x[0])\n",
        "            wave_size = waveform.size()[1]\n",
        "            samplesize = int(samplerate * duration)\n",
        "            start = 0\n",
        "            while True:\n",
        "                finish = start + samplesize\n",
        "                if finish < wave_size:\n",
        "                    dataset.append((x[0], start, finish, x[1]))\n",
        "                else:\n",
        "                    break\n",
        "                start = start + int(samplesize * (1 - overlap))\n",
        "        \n",
        "    random.shuffle(dataset)\n",
        "\n",
        "    #create a text file\n",
        "    with open(file_save, \"w\") as ft:\n",
        "        ft.write(\"audiofile, start, finish, label\" + \"\\n\")\n",
        "        for sample in dataset:\n",
        "            ft.write(str(sample)[1:-1] + \"\\n\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ4j5tGzba0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8ecd2b-4508-41d8-da33-5188a8c5f18d"
      },
      "source": [
        "classes = {\"Tamil\" : 1, \"Telugu\" : 2, \"Bengali\" : 3, \"Gujarathi\" : 0 }\n",
        "prepareData(\"/content/Languages\", classes, datatype=\"train\", duration=4, overlap=0.25, file_save=\"train_d2_o25.txt\")\n",
        "#preparing Test data\n",
        "prepareData(\"/content/Languages\", classes, datatype=\"test\", duration=4, overlap=0.25, file_save=\"test_d2_o25.txt\")\n",
        "print(\"Dataset was written to the specified files successfully\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset was written to the specified files successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPi9aOOuHNbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class LogMelSpec(nn.Module):\n",
        "    def __init__(self, sample_rate = 8000, n_mels=128, win_length=160, hop_length=80):\n",
        "        super(LogMelSpec, self).__init__()\n",
        "        self.transform = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=n_mels, win_length=win_length, hop_length=hop_length)\n",
        "\n",
        "    def forward(self, x):\n",
        "         x = self.transform(x)   # gets melspectrogram\n",
        "         x = np.log(x + 1e-14)    #smoothing to avoid infinity\n",
        "         return x\n",
        "\n",
        "\n",
        "# add time stretch and freq augmentations\n",
        "class SpecAugment(nn.Module):\n",
        "    def __init__(self, rate, strategy=3, freq_mask=10, time_mask=30):\n",
        "        super(SpecAugment, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "        self.specaug1 = nn.Sequential(\n",
        "            torchaudio.transforms.FrequencyMasking(freq_mask),\n",
        "            torchaudio.transforms.TimeMasking(time_mask)\n",
        "        )\n",
        "\n",
        "        self.specaug2 = nn.Sequential(\n",
        "            torchaudio.transforms.FrequencyMasking(freq_mask),\n",
        "            torchaudio.transforms.TimeMasking(time_mask),\n",
        "            torchaudio.transforms.FrequencyMasking(freq_mask),\n",
        "            torchaudio.transforms.TimeMasking(time_mask)\n",
        "        )\n",
        "\n",
        "        strategies = {1 : self.strategy1, 2 : self.strategy2, 3 : self.strategy3}\n",
        "        self._forward = strategies[strategy]\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward(x)\n",
        "        \n",
        "    def strategy1(self, x):\n",
        "        probability = torch.randn(1,1).item()\n",
        "        if self.rate > probability:\n",
        "            return self.specaug1(x)\n",
        "        return x\n",
        "        \n",
        "    def strategy3(self, x):\n",
        "        probability = torch.randn(1,1).item()\n",
        "        if probability > 0.5:\n",
        "            return self.strategy1(x)\n",
        "        return self.strategy2(x)\n",
        "        \n",
        "    def strategy2(self, x):\n",
        "        probability = torch.rand(1, 1).item()\n",
        "        if self.rate > 0.5:\n",
        "            return self.specaug2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AudioData(torch.utils.data.Dataset):\n",
        "    parameters = {\n",
        "        \"sample_rate\" : 8000,\n",
        "        \"n_feats\" : 81,\n",
        "        \"rateof_aug\" : 0.5,\n",
        "        \"aug_strategy\" : 3,\n",
        "        \"time_mask\" : 30,\n",
        "        \"freq_mask\" : 10,\n",
        "        \n",
        "    }\n",
        "\n",
        "    def __init__(self, datafile_path, sample_rate, n_feats, rateof_aug, aug_strategy, time_mask, freq_mask, valid=False, shuffle=True, log_ex=True):\n",
        "        \n",
        "        self.log_ex = log_ex\n",
        "\n",
        "        \n",
        "        if(type(datafile_path)==type(\"s\")):\n",
        "          print(\"Loaaa..ding data from \", datafile_path)\n",
        "          self.data = pd.read_csv(datafile_path, delimiter=',')\n",
        "        else:\n",
        "          self.data = datafile_path\n",
        "\n",
        "        if valid:\n",
        "            self.audio_transforms = torch.nn.Sequential(\n",
        "                LogMelSpec(sample_rate=sample_rate, n_mels=n_feats, win_length=160, hop_length=80)\n",
        "                )\n",
        "        else:\n",
        "            self.audio_transforms = torch.nn.Sequential(\n",
        "                LogMelSpec(sample_rate=sample_rate, n_mels=n_feats, win_length=160, hop_length=80),\n",
        "                SpecAugment(rateof_aug, aug_strategy, time_mask, freq_mask) \n",
        "            )\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.item()\n",
        "        \n",
        "        file_path = self.data.audiofile.iloc[index]\n",
        "        waveform, _ = torchaudio.load(file_path[1:-1])\n",
        "        label = self.data.iloc[index, 3]\n",
        "        start = self.data.iloc[index, 1]\n",
        "        finish = self.data.iloc[index, 2]\n",
        "        waveform = waveform[: , start : finish]\n",
        "        spectrogram = self.audio_transforms(waveform)\n",
        "        #spec_len = spectrogram.shape[-1] // 2\n",
        "        #label_len = 1\n",
        "        return spectrogram, label\n",
        "    \n",
        "    def describe(self):\n",
        "        return self.data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwqNhIBKA8Bz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd99b763-fa25-4943-9c18-c7753329af09"
      },
      "source": [
        "train = AudioData(\"./train_d2_o25.txt\", sample_rate=8000, n_feats=81, rateof_aug=0.5, aug_strategy=3, time_mask=30, freq_mask=10)\n",
        "print(len(train))\n",
        "test = AudioData(\"./test_d2_o25.txt\", sample_rate=8000, n_feats=81, rateof_aug=0.5, aug_strategy=3, time_mask=30, freq_mask=10, valid=True)\n",
        "print(len(test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaaa..ding data from  ./train_d2_o25.txt\n",
            "13744\n",
            "Loaaa..ding data from  ./test_d2_o25.txt\n",
            "3398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F-xwYKd7CWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828e803f-ffee-43a9-e6de-0b486bb16093"
      },
      "source": [
        "\n",
        "classes = {\"Tamil\" : 1, \"Telugu\" : 2, \"Bengali\" : 3, \"Gujarathi\" : 0}\n",
        "#import dataset\n",
        "batch_size = 32\n",
        "cuda = torch.cuda.is_available()\n",
        "print(cuda)\n",
        "if cuda:\n",
        "  torch.cuda.manual_seed(1)\n",
        "dataloader_args = dict(shuffle=True, batch_size=batch_size, num_workers=4) if cuda else dict(shuffle=True, batch_size=batch_size)\n",
        "train_loader = DataLoader(train,  **dataloader_args)\n",
        "test_loader = DataLoader(test, **dataloader_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcbCnKWzBerP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb4a3ca-dc32-49eb-e06a-1fb729f713a4"
      },
      "source": [
        "batch_size = 32\n",
        "cuda = torch.cuda.is_available()\n",
        "print(cuda)\n",
        "if cuda:\n",
        "  torch.cuda.manual_seed(1)\n",
        "dataloader_args = dict(shuffle=True, batch_size=batch_size, num_workers=4) if cuda else dict(shuffle=True, batch_size=batch_size)\n",
        "train_loader = DataLoader(train,  **dataloader_args)\n",
        "test_loader = DataLoader(test, **dataloader_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9eCtOgWQL2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a15e4c0-1ae1-4c8a-cb69-0d212bef3c50"
      },
      "source": [
        "print(type(train_loader))\n",
        "print(len(train_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.utils.data.dataloader.DataLoader\n",
            "13744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2praP6tpdm4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68d532f-3544-4148-e08e-9cd8536766f5"
      },
      "source": [
        "\n",
        "\n",
        "print(type(test_loader))\n",
        "print(len(test_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.utils.data.dataloader.DataLoader\n",
            "3398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCahxX8IUsrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFOafiCCzONQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "673a7bb2-97a6-4fa7-9f99-c5e6afabdbf6"
      },
      "source": [
        "sample[0].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 81, 401])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkXe8WTM3873",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997bc270-9a17-46d4-a1d2-76dfa3e108f6"
      },
      "source": [
        "sample = next(iter(test_loader))\n",
        "sample[0].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 81, 401])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qaZqCntQ4dI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7efab61-eb35-4d33-ac44-d8a14e20e9da"
      },
      "source": [
        "print(type(sample))\n",
        "print(sample[0][0].size())\n",
        "print(len(sample[0]))\n",
        "print(sample[0][1].size())\n",
        "print(len(sample[1]))\n",
        "print(sample[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "torch.Size([1, 81, 401])\n",
            "32\n",
            "torch.Size([1, 81, 401])\n",
            "32\n",
            "tensor([2, 3, 1, 3, 0, 1, 2, 3, 1, 1, 0, 1, 0, 0, 2, 2, 0, 0, 1, 3, 1, 0, 3, 0,\n",
            "        2, 1, 1, 3, 1, 1, 2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuBuC-Nz92Np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout_value = 0.06\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Convolution Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        ) # input_side = 28, output_size = 28, RF = 3\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        ) # output_size = 28, RF = 5\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12, RF = 6\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        ) # output_size = 12, RF = 10\n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        ) # output_size = 10, RF = 14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 12, RF = 6\n",
        "\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        ) # output_size = 8, RF = 18\n",
        "\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        ) # output_size = 6, RF = 22\n",
        "        self.pool3 = nn.MaxPool2d(2, 2) # output_size = 12, RF = 6\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(1,1), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        ) # output_size = 4, RF = 26\n",
        "        self.Convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(1,1), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.ReLU()\n",
        "        ) # \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.convblock9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=4, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            # nn.ReLU() NEVER!\n",
        "        ) # output_size = 1, RF = 26\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.pool1(x)\n",
        "        x1 = self.convblock3(x)\n",
        "        x2 = self.convblock4(x1)\n",
        "        x = self.pool2(x1+x2)\n",
        "        x1 = self.convblock5(x)\n",
        "        x2 = self.convblock6(x1)\n",
        "        x = self.fc1(self.pool3(x1+x2))\n",
        "        x = self.fc2(self.Convblock2(self.convblock7(x)))\n",
        "        x = self.convblock8(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock9(x)\n",
        "        x = x.view(-1, 4)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQyARlSp1sjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca719650-ae07-4207-c8c1-c2e7db21d669"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\")# if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "\n",
        "summary(model, input_size=(1, 81 , 81))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:104: UserWarning: \n",
            "Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
            "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
            "If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
            "\n",
            "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 81, 81]             144\n",
            "       BatchNorm2d-2           [-1, 16, 81, 81]              32\n",
            "           Dropout-3           [-1, 16, 81, 81]               0\n",
            "              ReLU-4           [-1, 16, 81, 81]               0\n",
            "            Conv2d-5           [-1, 32, 81, 81]           4,608\n",
            "       BatchNorm2d-6           [-1, 32, 81, 81]              64\n",
            "           Dropout-7           [-1, 32, 81, 81]               0\n",
            "              ReLU-8           [-1, 32, 81, 81]               0\n",
            "         MaxPool2d-9           [-1, 32, 40, 40]               0\n",
            "           Conv2d-10           [-1, 64, 40, 40]          18,432\n",
            "      BatchNorm2d-11           [-1, 64, 40, 40]             128\n",
            "          Dropout-12           [-1, 64, 40, 40]               0\n",
            "             ReLU-13           [-1, 64, 40, 40]               0\n",
            "           Conv2d-14           [-1, 64, 40, 40]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 40, 40]             128\n",
            "             ReLU-16           [-1, 64, 40, 40]               0\n",
            "        MaxPool2d-17           [-1, 64, 20, 20]               0\n",
            "           Conv2d-18          [-1, 128, 20, 20]          73,728\n",
            "      BatchNorm2d-19          [-1, 128, 20, 20]             256\n",
            "          Dropout-20          [-1, 128, 20, 20]               0\n",
            "             ReLU-21          [-1, 128, 20, 20]               0\n",
            "           Conv2d-22          [-1, 128, 20, 20]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 20, 20]             256\n",
            "          Dropout-24          [-1, 128, 20, 20]               0\n",
            "             ReLU-25          [-1, 128, 20, 20]               0\n",
            "        MaxPool2d-26          [-1, 128, 10, 10]               0\n",
            "           Conv2d-27           [-1, 64, 10, 10]           8,192\n",
            "      BatchNorm2d-28           [-1, 64, 10, 10]             128\n",
            "          Dropout-29           [-1, 64, 10, 10]               0\n",
            "             ReLU-30           [-1, 64, 10, 10]               0\n",
            "           Conv2d-31           [-1, 64, 10, 10]          36,864\n",
            "      BatchNorm2d-32           [-1, 64, 10, 10]             128\n",
            "          Dropout-33           [-1, 64, 10, 10]               0\n",
            "             ReLU-34           [-1, 64, 10, 10]               0\n",
            "           Conv2d-35             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-36             [-1, 64, 8, 8]             128\n",
            "          Dropout-37             [-1, 64, 8, 8]               0\n",
            "             ReLU-38             [-1, 64, 8, 8]               0\n",
            "           Conv2d-39             [-1, 32, 8, 8]           2,048\n",
            "      BatchNorm2d-40             [-1, 32, 8, 8]              64\n",
            "          Dropout-41             [-1, 32, 8, 8]               0\n",
            "             ReLU-42             [-1, 32, 8, 8]               0\n",
            "           Conv2d-43             [-1, 32, 8, 8]           9,216\n",
            "      BatchNorm2d-44             [-1, 32, 8, 8]              64\n",
            "          Dropout-45             [-1, 32, 8, 8]               0\n",
            "             ReLU-46             [-1, 32, 8, 8]               0\n",
            "AdaptiveAvgPool2d-47             [-1, 32, 1, 1]               0\n",
            "           Conv2d-48              [-1, 4, 1, 1]             128\n",
            "================================================================\n",
            "Total params: 375,920\n",
            "Trainable params: 375,920\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 19.53\n",
            "Params size (MB): 1.43\n",
            "Estimated Total Size (MB): 20.99\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWhDTE_p9fwf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72e1a92-5d4a-4cc1-9293-f2b142187031"
      },
      "source": [
        "print(torch.__version__)\n",
        "use_cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0.dev20200910+cu92\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5UdAIUSzukM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class ModelTrain():\n",
        "  def __init__(self):\n",
        "    #to monitor training and test losses\n",
        "    self.train_losses = []\n",
        "    self.test_losses = []\n",
        "    self.train_acc = []\n",
        "    self.test_acc = []\n",
        "    self.train_epoch_end = []\n",
        "    self.preds={}\n",
        "    # initialize tracker for minimum validation loss\n",
        "    self.valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "  def train(self, model, device, train_loader, optimizer, epoch,scheduler,  L1lambda=None):\n",
        "    model.train()    # prep model for training\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "      \n",
        "      # get samples\n",
        "      data, target = data.to(device), target.to(device)\n",
        "\n",
        "      # Init\n",
        "      optimizer.zero_grad()    # clear the gradients of all optimized variables\n",
        "      # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "      # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "      # Predict\n",
        "      y_pred = model(data)   # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      \n",
        "\n",
        "      # Calculate loss\n",
        "      loss = F.nll_loss(y_pred, target)\n",
        "      \n",
        "      #Implementing L1 regularization\n",
        "      if L1lambda is not None:\n",
        "        #l1_crit = nn.L1Loss(size_average=False)\n",
        "        reg_loss = 0.\n",
        "        for param in model.parameters():\n",
        "          #reg_loss += l1_crit(param)\n",
        "          reg_loss += torch.sum(param.abs())\n",
        "        loss += L1lambda * reg_loss\n",
        "\n",
        "      self.train_losses.append(loss)\n",
        "\n",
        "      # Backpropagation\n",
        "      loss.backward()   # backward pass: compute gradient of the loss with respect to model parameters\n",
        "      optimizer.step()   # perform a single optimization step (parameter update)\n",
        "\n",
        "      # Update pbar-tqdm\n",
        "    \n",
        "      pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "      processed += len(data)\n",
        "\n",
        "      pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "      self.train_acc.append(100*correct/processed)\n",
        "      scheduler.step()\n",
        "    self.train_epoch_end.append(self.train_acc[-1])\n",
        "\n",
        "\n",
        "  ####VAlidate the model ####\n",
        "  def test(self, model, device, test_loader, filename):\n",
        "    #valid_loss_min = np.Inf\n",
        "    model.eval()  # prep model for evaluation\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    self.preds={}\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)  # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            #test_loss += criterion(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            #print(target,pred)\n",
        "            for i in range(len(target)):\n",
        "              #print(target[i],pred[i])\n",
        "              if (target[i].item() not in self.preds):\n",
        "                self.preds[target[i].item()]=[pred[i][0].item()]\n",
        "              else:\n",
        "                self.preds[target[i].item()].append(pred[i][0].item())\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    self.test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    self.test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "\n",
        "    # save model if validation loss has decreased\n",
        "    if test_loss <= self.valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        self.valid_loss_min,\n",
        "        test_loss))\n",
        "        torch.save(model.state_dict(), filename)\n",
        "        self.valid_loss_min = test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XerbsD3QvjMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "def experimentation(duration,lr):\n",
        "  classes = {\"Tamil\" : 1, \"Telugu\" : 2, \"Bengali\" : 3, \"Gujarathi\" : 0 }\n",
        "  prepareData(\"/content/Languages\", classes, datatype=\"train\", duration=duration, overlap=0.25, file_save=\"train_d2_o25.txt\")\n",
        "  #preparing Test data\n",
        "  prepareData(\"/content/Languages\", classes, datatype=\"test\", duration=4, overlap=0.25, file_save=\"test_d2_o25.txt\")\n",
        "  print(\"Dataset was written to the specified files successfully\")\n",
        "  train = AudioData(\"./train_d2_o25.txt\", sample_rate=8000, n_feats=81, rateof_aug=0.5, aug_strategy=3, time_mask=30, freq_mask=10)\n",
        "  print(len(train))\n",
        "  test = AudioData(\"./test_d2_o25.txt\", sample_rate=8000, n_feats=81, rateof_aug=0.5, aug_strategy=3, time_mask=30, freq_mask=10, valid=True)\n",
        "  print(len(test))\n",
        "  classes = {\"Tamil\" : 1, \"Telugu\" : 2, \"Bengali\" : 3, \"Gujarathi\" : 0}\n",
        "  #import dataset\n",
        "  batch_size = 32\n",
        "  cuda = torch.cuda.is_available()\n",
        "  print(cuda)\n",
        "  if cuda:\n",
        "    torch.cuda.manual_seed(1)\n",
        "  dataloader_args = dict(shuffle=True, batch_size=batch_size, num_workers=4) if cuda else dict(shuffle=True, batch_size=batch_size)\n",
        "  train_loader = DataLoader(train,  **dataloader_args)\n",
        "  test_loader = DataLoader(test, **dataloader_args)\n",
        "  #from torch.optim.lr_scheduler import StepLR\n",
        "  #torch.cuda.empty_cache()\n",
        "  device = torch.device(\"cuda\")\n",
        "  model=Net().to(device)\n",
        "  from torch.optim.lr_scheduler import OneCycleLR\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "  #scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=15)\n",
        "  #first model\n",
        "  #without L1 and L2 regularization\n",
        "  model00 = ModelTrain()\n",
        "  EPOCHS = 15\n",
        "  for epoch in range(EPOCHS):\n",
        "    gc.collect()\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    model00.train(model, device, train_loader, optimizer, epoch, scheduler)\n",
        "    model00.test(model, device, test_loader, \"/content/drive/My Drive/LM6withAug.pt\")\n",
        "  global results\n",
        "  results.append([lr,duration,max(model00.test_acc)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLVjWaD_vY--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49a52bac-7b3a-4de0-e983-f7288b700e2f"
      },
      "source": [
        "results=[]\n",
        "durations=[2,3,4]\n",
        "lrs=[0.0725,0.1]\n",
        "for i in durations:\n",
        "  for j in lrs:\n",
        "    experimentation(i,j)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset was written to the specified files successfully\n",
            "Loaaa..ding data from  ./train_d2_o25.txt\n",
            "38680\n",
            "Loaaa..ding data from  ./test_d2_o25.txt\n",
            "3398\n",
            "True\n",
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.21890856325626373 Batch_id=1208 Accuracy=69.81: 100%|██████████| 1209/1209 [01:31<00:00, 13.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.1915, Accuracy: 1876/3398 (55.21%)\n",
            "\n",
            "Validation loss decreased (inf --> 1.191531).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.3191995322704315 Batch_id=1208 Accuracy=82.42: 100%|██████████| 1209/1209 [01:31<00:00, 13.27it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.5549, Accuracy: 2611/3398 (76.84%)\n",
            "\n",
            "Validation loss decreased (1.191531 --> 0.554903).  Saving model ...\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.8425745964050293 Batch_id=1208 Accuracy=87.29: 100%|██████████| 1209/1209 [01:31<00:00, 13.26it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6991, Accuracy: 2510/3398 (73.87%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.12474062293767929 Batch_id=1208 Accuracy=90.07: 100%|██████████| 1209/1209 [01:31<00:00, 13.25it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9396, Accuracy: 2078/3398 (61.15%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.3642864227294922 Batch_id=1208 Accuracy=91.97: 100%|██████████| 1209/1209 [01:30<00:00, 13.32it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.9445, Accuracy: 1671/3398 (49.18%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.36640605330467224 Batch_id=1208 Accuracy=93.54: 100%|██████████| 1209/1209 [01:30<00:00, 13.41it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6030, Accuracy: 2658/3398 (78.22%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.021672239527106285 Batch_id=1208 Accuracy=94.08: 100%|██████████| 1209/1209 [01:31<00:00, 13.19it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.5800, Accuracy: 2700/3398 (79.46%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.18791402876377106 Batch_id=1208 Accuracy=95.26: 100%|██████████| 1209/1209 [01:33<00:00, 12.95it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.0681, Accuracy: 2426/3398 (71.39%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.15497910976409912 Batch_id=1208 Accuracy=95.70: 100%|██████████| 1209/1209 [01:33<00:00, 12.93it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8558, Accuracy: 2439/3398 (71.78%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08302166312932968 Batch_id=1208 Accuracy=96.16: 100%|██████████| 1209/1209 [01:31<00:00, 13.17it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7681, Accuracy: 2477/3398 (72.90%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11939247697591782 Batch_id=1208 Accuracy=96.85: 100%|██████████| 1209/1209 [01:31<00:00, 13.17it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9068, Accuracy: 2477/3398 (72.90%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06185821816325188 Batch_id=1208 Accuracy=97.48: 100%|██████████| 1209/1209 [01:31<00:00, 13.22it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7766, Accuracy: 2569/3398 (75.60%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.007368836086243391 Batch_id=1208 Accuracy=98.09: 100%|██████████| 1209/1209 [01:31<00:00, 13.19it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7442, Accuracy: 2633/3398 (77.49%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06222523748874664 Batch_id=1208 Accuracy=98.28: 100%|██████████| 1209/1209 [01:31<00:00, 13.15it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8507, Accuracy: 2543/3398 (74.84%)\n",
            "\n",
            "EPOCH: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.004637116100639105 Batch_id=1208 Accuracy=98.46: 100%|██████████| 1209/1209 [01:32<00:00, 13.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7624, Accuracy: 2601/3398 (76.55%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset was written to the specified files successfully\n",
            "Loaaa..ding data from  ./train_d2_o25.txt\n",
            "38680\n",
            "Loaaa..ding data from  ./test_d2_o25.txt\n",
            "3398\n",
            "True\n",
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.5448221564292908 Batch_id=1208 Accuracy=70.38: 100%|██████████| 1209/1209 [01:32<00:00, 13.12it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 3.5927, Accuracy: 1374/3398 (40.44%)\n",
            "\n",
            "Validation loss decreased (inf --> 3.592749).  Saving model ...\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.9347822666168213 Batch_id=1208 Accuracy=82.01: 100%|██████████| 1209/1209 [01:32<00:00, 13.02it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.0232, Accuracy: 2098/3398 (61.74%)\n",
            "\n",
            "Validation loss decreased (3.592749 --> 1.023165).  Saving model ...\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.6146601438522339 Batch_id=1208 Accuracy=86.66: 100%|██████████| 1209/1209 [01:33<00:00, 12.93it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9817, Accuracy: 2250/3398 (66.22%)\n",
            "\n",
            "Validation loss decreased (1.023165 --> 0.981747).  Saving model ...\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.2666407525539398 Batch_id=1208 Accuracy=89.45: 100%|██████████| 1209/1209 [01:31<00:00, 13.17it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7466, Accuracy: 2473/3398 (72.78%)\n",
            "\n",
            "Validation loss decreased (0.981747 --> 0.746615).  Saving model ...\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.4356551170349121 Batch_id=1208 Accuracy=91.52: 100%|██████████| 1209/1209 [01:31<00:00, 13.25it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9032, Accuracy: 2521/3398 (74.19%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.5980989933013916 Batch_id=1208 Accuracy=92.68: 100%|██████████| 1209/1209 [01:31<00:00, 13.17it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.2668, Accuracy: 2086/3398 (61.39%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06948748975992203 Batch_id=1208 Accuracy=93.75: 100%|██████████| 1209/1209 [01:32<00:00, 13.11it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9994, Accuracy: 2280/3398 (67.10%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09696058183908463 Batch_id=1208 Accuracy=94.75: 100%|██████████| 1209/1209 [01:35<00:00, 12.64it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.0391, Accuracy: 2219/3398 (65.30%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.050333794206380844 Batch_id=1208 Accuracy=95.40: 100%|██████████| 1209/1209 [01:33<00:00, 12.97it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9742, Accuracy: 2287/3398 (67.30%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04243985190987587 Batch_id=1208 Accuracy=95.94: 100%|██████████| 1209/1209 [01:32<00:00, 13.11it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.4625, Accuracy: 2179/3398 (64.13%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01749628782272339 Batch_id=1208 Accuracy=96.41: 100%|██████████| 1209/1209 [01:33<00:00, 12.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7268, Accuracy: 2663/3398 (78.37%)\n",
            "\n",
            "Validation loss decreased (0.746615 --> 0.726756).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.002000445267185569 Batch_id=1208 Accuracy=97.18: 100%|██████████| 1209/1209 [01:33<00:00, 12.92it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8193, Accuracy: 2496/3398 (73.45%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07247444242238998 Batch_id=1208 Accuracy=97.75: 100%|██████████| 1209/1209 [01:32<00:00, 13.08it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8950, Accuracy: 2472/3398 (72.75%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.008475718088448048 Batch_id=1208 Accuracy=98.22: 100%|██████████| 1209/1209 [01:32<00:00, 13.13it/s]\n",
            "  0%|          | 0/1209 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8966, Accuracy: 2476/3398 (72.87%)\n",
            "\n",
            "EPOCH: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.1281672567129135 Batch_id=1208 Accuracy=98.45: 100%|██████████| 1209/1209 [01:33<00:00, 12.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8996, Accuracy: 2486/3398 (73.16%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset was written to the specified files successfully\n",
            "Loaaa..ding data from  ./train_d2_o25.txt\n",
            "22195\n",
            "Loaaa..ding data from  ./test_d2_o25.txt\n",
            "3398\n",
            "True\n",
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.4122655689716339 Batch_id=693 Accuracy=69.95: 100%|██████████| 694/694 [01:08<00:00, 10.21it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.3562, Accuracy: 1596/3398 (46.97%)\n",
            "\n",
            "Validation loss decreased (inf --> 1.356185).  Saving model ...\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.6501451730728149 Batch_id=693 Accuracy=82.52: 100%|██████████| 694/694 [01:08<00:00, 10.17it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 2.0615, Accuracy: 2231/3398 (65.66%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.39775583148002625 Batch_id=693 Accuracy=87.10: 100%|██████████| 694/694 [01:08<00:00, 10.13it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8436, Accuracy: 2464/3398 (72.51%)\n",
            "\n",
            "Validation loss decreased (1.356185 --> 0.843631).  Saving model ...\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.17115674912929535 Batch_id=693 Accuracy=89.85: 100%|██████████| 694/694 [01:08<00:00, 10.07it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.5706, Accuracy: 1811/3398 (53.30%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09532701969146729 Batch_id=693 Accuracy=92.22: 100%|██████████| 694/694 [01:08<00:00, 10.09it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.3249, Accuracy: 2319/3398 (68.25%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04292144253849983 Batch_id=693 Accuracy=93.65: 100%|██████████| 694/694 [01:08<00:00, 10.17it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8899, Accuracy: 2447/3398 (72.01%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06558562815189362 Batch_id=693 Accuracy=94.57: 100%|██████████| 694/694 [01:08<00:00, 10.09it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8983, Accuracy: 2419/3398 (71.19%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.19374501705169678 Batch_id=693 Accuracy=95.48: 100%|██████████| 694/694 [01:08<00:00, 10.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8340, Accuracy: 2460/3398 (72.40%)\n",
            "\n",
            "Validation loss decreased (0.843631 --> 0.834046).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.21229799091815948 Batch_id=693 Accuracy=96.17: 100%|██████████| 694/694 [01:08<00:00, 10.14it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6903, Accuracy: 2639/3398 (77.66%)\n",
            "\n",
            "Validation loss decreased (0.834046 --> 0.690269).  Saving model ...\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0072287446819245815 Batch_id=693 Accuracy=96.89: 100%|██████████| 694/694 [01:09<00:00,  9.98it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7364, Accuracy: 2621/3398 (77.13%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.004025834146887064 Batch_id=693 Accuracy=97.46: 100%|██████████| 694/694 [01:10<00:00,  9.80it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8540, Accuracy: 2572/3398 (75.69%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.024791309610009193 Batch_id=693 Accuracy=97.96: 100%|██████████| 694/694 [01:11<00:00,  9.69it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.1596, Accuracy: 2468/3398 (72.63%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.009643567726016045 Batch_id=693 Accuracy=98.34: 100%|██████████| 694/694 [01:12<00:00,  9.53it/s]\n",
            "  0%|          | 0/694 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9349, Accuracy: 2685/3398 (79.02%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.1104130670428276 Batch_id=229 Accuracy=98.61:  33%|███▎      | 228/694 [00:24<00:52,  8.86it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KScPdLew5-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "149a188e-fbe3-41e1-94f6-ab30c325d0cc"
      },
      "source": [
        "results"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0725, 2, 79.45850500294291],\n",
              " [0.1, 2, 78.36962919364332],\n",
              " [0.0725, 3, 79.01706886403767],\n",
              " [0.1, 3, 83.31371394938199],\n",
              " [0.0725, 4, 80.40023543260742],\n",
              " [0.1, 4, 83.5197174808711]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V73XCaZXTBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(4):\n",
        "  print(i,(model00.preds[i].count(i)/len(model00.preds[i]))*100)\n",
        "  '''for j in range(4):\n",
        "    print(i,j,model00.preds[i].count(j))'''\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvhF4uHIYd_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(model00.test_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiLyb8qAZc0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wave_form, sample_rate = torchaudio.load('./Languages/Bengali/Bengali_Train/Bengali1764.wav')\n",
        "\n",
        "specgram = torchaudio.transforms.MelSpectrogram(win_length=256,hop_length=256)(wave_form[0:3200])\n",
        "print(type(specgram))\n",
        "\n",
        "print(\"Shape of spectrogram: {}\".format(specgram.size()))\n",
        "\n",
        "plt.figure()\n",
        "p = plt.imshow(specgram.log2()[0,:,:].detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Fdkxgfa8ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {\n",
        "        \"sample_rate\" : 8000,\n",
        "        \"n_feats\" : 81,\n",
        "        \"rateof_aug\" : 0.5,\n",
        "        \"aug_strategy\" : 3,\n",
        "        \"time_mask\" : 30,\n",
        "        \"freq_mask\" : 10,\n",
        "        \n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SReMM5i3Z8Wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_transforms = torch.nn.Sequential(\n",
        "                LogMelSpec(sample_rate=8000, n_mels=128, win_length=256, hop_length=256),\n",
        "                SpecAugment(0.5, 3,30, 10) \n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVlo2i7VawsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wave_form, sample_rate = torchaudio.load('./Languages/Bengali/Bengali_Train/Bengali1764.wav')\n",
        "\n",
        "specgram = audio_transforms(wave_form[0:3200])\n",
        "print(type(specgram))\n",
        "\n",
        "print(\"Shape of spectrogram: {}\".format(specgram.size()))\n",
        "\n",
        "plt.figure()\n",
        "p = plt.imshow(specgram[0,:,:].detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}